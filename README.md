# federated_learning_posinoning_attack
Federated Learning Poisoning Attack Simulation – Three clients train local models, and a federated learner aggregates results. By replacing Client 3’s dataset with poisoned data, the global accuracy drops. Includes an SSH brute-force script to simulate remote compromise and data injection.
